{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Assignment_10_Solutions.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabriceBeaumont/4216_Biomedical_DS_and_AI/blob/main/Sheet10/Assignment_10_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9UZQvv0GGYB"
      },
      "source": [
        "## Biomedical Data Science & AI\n",
        "\n",
        "## Assignment 10\n",
        "\n",
        "#### Group members:  Fabrice Beaumont, Fatemeh Salehi, Genivika Mann, Helia Salimi, Jonah"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP7FPcuSGGYE"
      },
      "source": [
        "**Exercise 1 - Variational Autoencoders (VAEs) (12 points)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZHUAvoBGGYG"
      },
      "source": [
        "**1. Explain how far a VAE’s lower dimension representation differs from that learned\n",
        "by a traditional autoencoder. How is that achieved? How far does the training\n",
        "objective differ? (2 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWodsOwzGGYJ"
      },
      "source": [
        "- Traditional autoencoders use the datapoints directly for encoding and minimising the reconstruction error without enforcing any organisation in the latent space(lower dimensional representation). VAE's on the other hand, assume that the input data belongs to a probability distribution over the latent space(lower dimensional representation) and attempts to find the parameters of that distribution. It maps each data point to a Gaussian distribution. This produces a smooth manifold embedding in latent space.\n",
        "\n",
        "\n",
        "- Since traditional autoencoders do not learn a probability distribution hence the mapping generated by traditional autoencoders could be discontinuous (indicated by presence of gaps in the latent space). VAE's have smooth interpolation between different groups.\n",
        "\n",
        "\n",
        "- Autoencoders cannot be used to generate new content. VAE's can be used as a generative system as they can produce new data which is related to original inputs. VAE's can be considered as autoencoders whose training process is regularised to avoid overfitting and latent space has the properties to enable generative process.\n",
        "\n",
        "\n",
        "- In traditional autoencoders, each hidden layer represents a non-linear mapping of previous layer.\n",
        "$$\n",
        "z = s(Wx+b)\n",
        "$$\n",
        "The decoder is responsible for reconstructing the input using the output of the encoder.\n",
        "$$\n",
        "y = s(W'z+b')\n",
        "$$\n",
        "The objective is to minimise the reconstruction error which is done by gradient descent over the parameters of the encoder and decoder neural networks.\n",
        "\n",
        "$$\n",
        "\\text{arg min}_{W, W', b, b'}\\ l(x_i, y_i)\n",
        "$$\n",
        "Possible loss functions can be squared error or cross entropy for binary data.\n",
        "\n",
        "\n",
        "- The training objective of VAE's consists of a reconstruction error term and regularisation term. It is given by:\n",
        "\n",
        "$$\n",
        "\\tilde{L}(\\theta, \\phi, x^{(i)}) = \\frac{1}{2} \\sum_{j = 1}^{J}\\left(1+log((\\sigma_j^{(i)})^2))- (\\mu_j^{(i)}))^2 - (\\sigma_j^{(i)}))^2 \\right) + \\frac{1}{L} \\sum_{l = 1}^{L}\\left(log p_\\theta(x^{(i)}|z^{(i,l)})\\right)\n",
        "$$\n",
        "\n",
        "where J = mini-batch size and L = no. of samples\n",
        "\n",
        "- Traditional autoencoders do not balance regularity (structures of latent space are intrepretable and exploitable) and reconstruction error(important information of the data must not be lost after dimensionality reduction). The VAE objective function is able to achieve this by balancing reconstruction accuracy and deviation from prior distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeaJ0CDqGGYM"
      },
      "source": [
        "**2. Inform yourself about the applications of autoencoders in the biomedical field.\n",
        "Explore the literature, then mention one application and explain how it works. (2\n",
        "points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB_q_w4aGGYO"
      },
      "source": [
        "- In the paper titled ***'Automatic Sleep Stage Scoring Using Time-Frequency Analysis and Stacked Sparse Autoencoders'*** by Tsinalis et al $^{[1]}$, a methodolgy has been developed for automatic sleep stage scoring. An openly available dataset containing EEG data of 20 healthy young adults was used in this literature. In order to ensure that the results of this study were suitable for longitudinal monitoring using wearable EEG in real world setting, only a single channel of EEG from the dataset was used for construction of the model. Sleep was classified into 5 stages namely - N1, N2, N3, R and W.\n",
        "\n",
        "\n",
        "- Time frequency analysis based feature extraction is fine tuned to capture sleep stage specific signal features. Sleep stages are then classified using ensemble learning with an ensemble of stacked sparse autoencoders. For each model, class balanced random sampling across sleep stages was performed to deal with any class imbalance in the dataset.\n",
        "\n",
        "\n",
        "- The hyperparameter values were fixed to $\\lambda = 1 * 10^{-15}$, $\\beta = 2.0$, $\\rho=0.2$ and n = 20 (units of hidden layer), r = 60 (no. of optimisation iterations). The features were transformed so that distribution is approximately centered around mean hence sigmoid activation function was used for autoencoders. The final model consisted of an ensemble of 20 SSAEs(Stacked Sparse Autoencoders) having same hyperparameters. The results were evaluated using 20 fold cross validation.\n",
        "\n",
        "\n",
        "- The method achieved an overall accuracy in range 75-80%, high mean F1-score in range 82-86% and mean accuracy across individual sleep stages in range 84-88% over all subjects. This is a relevant application of Autoencoders as detection of sleep/circadian distruption can be vital in recognising early stages of neurodegenerative diseases such as Alzheimer's disease, Parkinson's disease, etc and sleep stabilisation can improve patient's quality of life.\n",
        "\n",
        "**References:**\n",
        "- Tsinalis, O., Matthews, P.M. & Guo, Y. Automatic Sleep Stage Scoring Using Time-Frequency Analysis and Stacked Sparse Autoencoders. Ann Biomed Eng 44, 1587–1597 (2016)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ9OIIfpGGYR"
      },
      "source": [
        "**3. Inform yourself about VAE variants, then explain the modifications and uses of\n",
        "the following variants:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54cGJeKqGGYT"
      },
      "source": [
        "**a. Beta-VAE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgH5EjSKhjDU"
      },
      "source": [
        "The Beta- VAE uses the Lagrange multiplier on the KL divergence term in the original VAE training objective. The objective function of Beta-VAE is:\n",
        "\n",
        "$$\n",
        "\\mathbb{L} ={\\mathbb{E}_{q(z|X)}[log{p(X | z)}] – \\beta D_{KL}(q(z | X) || p(z))}\n",
        "$$\n",
        "\n",
        "\n",
        "This variant of VAE is used for disentangled factor learning that can discover the independant latent factors of variation in unsupervised data. It modifies VAE with an adjustable hyperparameter $\\beta$ that balances latent channel capacity and independant constraints with reconstruction accuracy. It attempts to maximise probability of generating real data while keeping the distance between real and estimated distributions small, under threshold $\\epsilon$. It weights the regularisation term to increase the interpretability of the model, however this would result in a decrease in the reconstruction accuracy as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ00tfoFGGYX"
      },
      "source": [
        "**b. Vector Quantised-VAE (VQ-VAE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c9lVU49hnUZ"
      },
      "source": [
        "It is a type of variational autoencoder which uses vector quantisation to obtain discrete latent embeddings. Unlike VAE, in VQ-VAE the encoder outputs discrete codes, the posterior and prior distributions are categorical and the samples drawn from these distributions index an embedding table.\n",
        "\n",
        "It uses the Vector Quantisation method which enables the model to circumvent issues of posterior collapse. VQ-VAE is useful for modeling discrete representations such as in problems related language, speech, etc.The loss function is as follows:\n",
        "$$\n",
        "\\mathbb{L} = ||x - D(e_k)||^2_2 + ||sg[E(x)] - e_k||^2_2 + \\beta||E(x) - sg[e_k]||^2_2\n",
        "$$\n",
        "\n",
        "where sg is the stop_gradient operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUcBHrZ3hqpU"
      },
      "source": [
        "**4. Load the MNIST digits dataset from Keras datasets API. Normalize all your\n",
        "values between 0 and 1, and flatten your images into vectors of size 784. Build a\n",
        "simple VAE model using the following architecture:**\n",
        "\n",
        "\n",
        "**a. Encoder: 1 hidden layer with an input, using ReLU activation function (1\n",
        "point)**\n",
        "\n",
        "\n",
        "**b. Decoder: 1 hidden layer using sigmoid activation function (1 point)\n",
        "Your encoder should take an image input of 784 floats and encode it to 32 floats,\n",
        "while the decoder should take the encoded input and reconstruct an image of\n",
        "784 floats. Compile your model using the following:**\n",
        "\n",
        "\n",
        "**1. Adam optimizer (0.5 point)**\n",
        "\n",
        "\n",
        "**2. Binary cross entropy loss function (0.5 point)**\n",
        "\n",
        "\n",
        "**Train your model using the following parameters:**\n",
        "\n",
        "\n",
        "**1. 50 epochs (0.5 point)**\n",
        "\n",
        "\n",
        "**2. Batch size of 256 (0.5 point)**\n",
        "\n",
        "\n",
        "**Use your model to predict 10 digits from the MNIST dataset, then plot the original\n",
        "and reconstructed images for reference. (2 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "x_gdMDd4hrur",
        "outputId": "d2a2f18e-b3c0-4a7d-ed5f-dc5dd50c7730"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# load dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# normalise values between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# flatten images into vector of size 784\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "encoding_dim = 32 \n",
        "\n",
        "input_img = keras.Input(shape=(784,)) # input image\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(input_img) # encoded representation of input\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded) # decoded representation of input\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded) # mapping input to reconstruction\n",
        "\n",
        "encoder = keras.Model(input_img, encoded) # encoder model\n",
        "encoded_input = keras.Input(shape=(encoding_dim,)) # encoded input\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input)) # decoder model\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# train autoencoder for 50 epochs\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                verbose = 0,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# encode-decode digits\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "n = 10 \n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUC2udauJAZw"
      },
      "source": [
        "**Exercise 2 - Generative Adversarial Networks (GANs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu_2noeYJSiI"
      },
      "source": [
        "**1. What are the specific properties of GANs in comparison to VAEs?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dHxq15fJXQM"
      },
      "source": [
        "- The images of the VAE are blurry and no realistic objects can be recognized. The GAN generates images with sharper edges. The GAN produces much sharper images than the VAE.\n",
        "- he faces produced by the VAE own a more natural appearance.<br>\n",
        "- The main difference between VAEs and GANs is their learning process. VAEs are minimizing a loss reproducing a certain image, and can, therefore, be considered as solving a semisupervised learning problem. GANs, on the other hand, are solving an unsupervised learning problem.\n",
        "- The most important difference found is the training time for the two methods. GANs took longer time to train. Therefore the use of GANs is considered and proved a lot more stable. With GANs this does not necessarily occur. For low-diversity datasets like MNIST, both methods give sufficiently realistic images.\n",
        "- Finally, using VAEs one can achieve results in less time, but with decreased image quality compared to results of GANs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJsVPWYeJaoG"
      },
      "source": [
        "**2. Familiarize yourself with the following type of GANS and briefly explain how each technique differs from vanilla GANs and give an application example for each type.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNKSHeNlJmb9"
      },
      "source": [
        "**a. Deep Convolutional GANs (DCGANs)**\n",
        "\n",
        "The deep convolutional generative adversarial network, or DCGAN for short, is an extension of the GAN architecture for using deep convolutional neural networks for both the generator and discriminator models and configurations for the models and training that result in the stable training of a generator model.\n",
        "\n",
        "The DCGAN is important because it suggested the constraints on the model required to effectively develop high-quality generator models in practice. This architecture, in turn, provided the basis for the rapid development of a large number of GAN extensions and applications.\n",
        "\n",
        "Application Example:\n",
        "\n",
        "Generate Cartoon Characters: training and use of a DCGAN for generating faces of anime characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s92X4ZXXJtpW"
      },
      "source": [
        "**b. Wasserstein GANs (WGANs)**\n",
        "\n",
        "The Wasserstein generative adversarial network, or WGAN for short, is an extension to the GAN that changes the training procedure to update the discriminator model, now called a critic, many more times than the generator model for each iteration.\n",
        "\n",
        "The critic is updated to output a real-value (linear activation) instead of a binary prediction with a sigmoid activation, and the critic and generator models are both trained using “Wasserstein loss,” which is the average of the product of real and predicted values from the critic, designed to provide linear gradients that are useful for updating the model.\n",
        "\n",
        "In addition, the weights of the critic model are clipped to keep them small, e.g. a bounding box of $[-0.01. 0.01]$.\n",
        "\n",
        "In order to have parameters $w$ lie in a compact space, something simple we can do is clamp the weights to a fixed box (say $W = [−0.01, 0.01]$ ) after each gradient update.\n",
        "\n",
        "The benefit of the WGAN is that the training process is more stable and less sensitive to model architecture and choice of hyperparameter configurations. Perhaps most importantly, the loss of the discriminator appears to relate to the quality of images created by the generator.\n",
        "\n",
        "Application Example:\n",
        "\n",
        "Distinguish hand-written digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhx4RIOdJt1s"
      },
      "source": [
        "**c. Self-Attention GANs (SAGANs)**\n",
        "\n",
        "A Self-attention GAN is a DCGAN that utilizes self-attention layers. The idea of self-attention has been out there for years, also known as non-local in some researches. \n",
        "Convolution works by convolving nearby pixels and extracting features out of local blocks. They work “locally” in each layer. In contrast, self-attention layers learn from distant blocks.\n",
        "\n",
        "Application Example:\n",
        "\n",
        "To refine the image quality of the eye region (the red dot on the left figure), SAGAN only uses the feature map region on the highlight area in the middle figure. This region has a larger receptive field and the context is more focus and more relevant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF41syBlJumP"
      },
      "source": [
        "**d. BigGANs**\n",
        "\n",
        "The big generative adversarial network, or BigGAN for short, is an approach that demonstrates how high-quality output images can be created by scaling up existing class-conditional GAN models.\n",
        "\n",
        "The model architecture is based on a collection of best practices across a wide range of GAN models and extensions. Further improvements are achieved through systematic experimentation.\n",
        "\n",
        "A “truncation trick” is used where points are sampled from a truncated Gaussian latent space at generation time that is different from the untruncated distribution at training time.\n",
        "\n",
        "Application Example:\n",
        "\n",
        "Generate Realistic Photographs: generation of synthetic photographs with technique BigGAN that are practically indistinguishable from real photographs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8lzMzLmi5Xc"
      },
      "source": [
        "**Exercise 3 - LSTMs & Transformers (7 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpwnNs4wi8Xo"
      },
      "source": [
        "**1. General architecture of LSTM unit**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PMVdA8blONT"
      },
      "source": [
        "- Each LSTM unit transfers two states namely cell state and hidden state to the next unit. The unit is responsible for taking input and storing it for some it and it does so using 3 mechanisms called gates.\n",
        "\n",
        "- **Forget Gate:**  ($f_t$) It controls the extent to which a value remains in the unit. It takes two inputs This gate takes in two inputs -  $h_t-1$ and $x_t$.The given inputs are multiplied by the weight matrices and a bias is added. Following this, the sigmoid function is applied to this value. The sigmoid function outputs a vector, with values ranging from 0 to 1, corresponding to each number in the cell state.\n",
        "\n",
        "- **Input Gate:**($i_t$) It controls the extent to which a new value flows into the unit. It adds information to the cell states using 3 steps:\n",
        "  - Regulating what values need to be added to the cell state by involving a sigmoid function. \n",
        "  - Using tanh function and creating a vector containing all possible values that can be added (as perceived from h_t-1 and x_t) to the cell state.\n",
        "  - Multiplying the value of the regulatory filter (the sigmoid gate) to the created vector (the tanh function) and then adding this useful information to the cell state via addition operation\n",
        "\n",
        "- **Output Gate:**($o_t$) It controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit. It creates a vector after applying tanh function to the cell state. It then makes  a filter using sigmoid function using the values of h_t-1 and x_t, such that it can regulate the values that need to be output from the vector created above. Following this it multiplies the value of this regulatory filter to the vector created in step 1, and sending it out as a output and also to the hidden state of the next cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8grqF9OBo2Q2"
      },
      "source": [
        "**2. What is a Bidirectional LSTM? And what are its advantages over a classical LSTM?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ-AyilGpATP"
      },
      "source": [
        "Classical LSTMs only read information from the past i.e in forward direction. Bidirectional LSTMs train two LSTMs on the input sequence. The first LSTM takes the input in a forward direction and the other in the backward direction. They increase the amount of information available to the network due to two-passes and hence provide greater context to the algorithm as compared to classical LSTMs. This results in faster and ever-fuller learning on the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8O2O9BDr0AV"
      },
      "source": [
        "**3. Both transformers and LSTMs retain memory of the generated output .What are the differences between transformers and LSTMs, and what are the advantages of transformers compared to LSTMs?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQfcGxppr9_c"
      },
      "source": [
        "Transformers make use of the attention mechanism, which involves assigning greater importance(weight) to certain parts of the input sequence. They are used to handle sequential data like LSTMS, however they do not process the input data in order. The attention mechanism provides context for any position in the input sequence. This allows for parallelisation and reduces training times making it possible to train on larger datasets which was not possible with LSTM.They are also useful for time series forecasting"
      ]
    }
  ]
}