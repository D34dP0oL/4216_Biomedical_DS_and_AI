{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Assignment9_Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabriceBeaumont/4216_Biomedical_DS_and_AI/blob/main/Sheet9/Assignment9_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UnHoHsFop-8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict, train_test_split\n",
        "from sklearn.calibration import calibration_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUswbzmRCHbj"
      },
      "source": [
        "def get_dataset_from_github(filename, index_col_str=None, header_str='infer'):    \n",
        "    data_file_path = \"https://raw.githubusercontent.com/FabriceBeaumont/4216_Biomedical_DS_and_AI/tree/main/Datasets\"\n",
        "    if index_col_str is None and header_str == 'infer':\n",
        "      data = pd.read_csv(data_file_path + filename)\n",
        "    elif index_col_str is None:\n",
        "        data = pd.read_csv(data_file_path + filename, header=header_str)\n",
        "    elif header_str == 'infer':\n",
        "      data = pd.read_csv(data_file_path + filename, index_col=index_col_str)\n",
        "    else:\n",
        "      data = pd.read_csv(data_file_path + filename, index_col=index_col_str, header=header_str)\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Q3YXStZTEQGa",
        "outputId": "8cf94bee-6c40-4ef3-ccc3-1e1940198a32"
      },
      "source": [
        "# titanic_survival_ds = get_dataset_from_github(\"/titanic_survival_data.csv\")\n",
        "# If this does not work, load the file (temporarily) into the Colab-File system (left side) \n",
        "# from your local files. Then execute as usual:\n",
        "titanic_survival_ds = pd.read_csv(\"titanic_survival_data.csv\")\n",
        "\n",
        "titanic_survival_ds.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>no_cabin</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  Sex   Age  ...     Fare  Embarked  no_cabin  Label\n",
              "0            1       3    0  22.0  ...   7.2500         0         2      0\n",
              "1            2       1    1  38.0  ...  71.2833         1         1      1\n",
              "2            3       3    1  26.0  ...   7.9250         0         2      1\n",
              "3            4       1    1  35.0  ...  53.1000         0         1      1\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx0G72bGl7xc"
      },
      "source": [
        "## Biomedical Data Science & AI\n",
        "\n",
        "## Assignment 8\n",
        "\n",
        "#### Group members:  Fabrice Beaumont, Fatemeh Salehi, Genivika Mann, Helia Salimi, Jonah"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fhYMe5ml7xo"
      },
      "source": [
        "---\n",
        "### Exercise 1 - Ensemble Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_krKhWqo-Bv7"
      },
      "source": [
        "#### 1.1. Inform yourself about **gradient boosting**, then answer the following questions in your own words:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTjkofc690tY"
      },
      "source": [
        "In-depth resource for Gradient Boosting: https://explained.ai/gradient-boosting/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYHqa8s-92O3"
      },
      "source": [
        "Gradient Boosting is a machine learning technique which uses Gradient Descent and Boosting. It aims at fitting an additive model by introducing **weak learners** (i.e Decision trees) such that the recently added weak learner compensates the shortcomings of existing weak learners. The shortcoming of existing weak learners are identified by gradients in the loss function. Any user specified loss function can be optimised by a gradient boosting algorithm. The objective is to minimise the loss function by adding weak learners using Gradient Descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgUkN-nGziCe"
      },
      "source": [
        "a. What do the individual **weak learners** model? How does this relate to the\n",
        "gradient of the loss function?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKBxLpeY-Wf6"
      },
      "source": [
        "- The weak learners are trained with the objective of minimising the loss function, hence they are trained on the residuals of the model. Each new weak learner will be fitted on the **residual error** usually known as **pseudo-residual** produced by the existing sequence of learners.\n",
        "\n",
        "- The gradient boosting algorithm performs **gradient descent minimisation on some loss function** between the true and the predicted values. We perform gradient descent to bring the predicted values closer to the true value by minimising the residual. The residual is a vector which not only provides the magnitude of difference between the true and the predicted value but also the direction of better approximation (w.r.t. minimization of loss function). Hence we are chasing the (negative) gradient of the loss function via gradient descent by chasing the direction of residual. Thus we perform gradient descent on the loss function.\n",
        "\n",
        "- The gradient boosted model that trains weak learners on residual vectors optimises the mean squared error (MSE; $L_2$ loss), ...\n",
        "\n",
        "- ...while the model that trains the weak learners on the sign vector (only direction of residual without the magnitude) optimises the mean absolute error(MAE; $L_1$ loss)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh-CgF8k-JLD"
      },
      "source": [
        "b. What is the difference between **gradient boosting** and **random forest**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZivxSdGg-l9T"
      },
      "source": [
        "- Gradient Boosting (GB) is a forward stage-wise additive model, that builds and adds one tree at a time with the objective of minimising the loss function (computed by considering the existing sequence of trees). Random forest (RF) on the other hand builds all trees independently - using random samples of the data (to prevent overfitting).\n",
        "\n",
        "\n",
        "- GB focusses step by step on difficult examples - making it suitable for datasets with class imbalance. No such quality is present in RF. Additionally, any user specified loss function can be optimised by a gradient boosting algorithm.\n",
        "\n",
        "\n",
        "- RF combines the results of all the trees at the end after the construction of all trees. GB on the other hand, takes the predictions of the sequence of trees into consideration at each stage of the algorithm.\n",
        "\n",
        "\n",
        "- If the parameters are tuned carefully, GB can perform better than RF. However it is difficult to tune GB since there are much more parameters that need to be tuned.\n",
        "\n",
        "\n",
        "- GB is more sensitive to overfitting if the data is noisy. RF is more robust and should be considered in this case.\n",
        "\n",
        "\n",
        "- Training GB generally takes longer then RF, since the trees are constructed sequentially."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appoDszfFI5l"
      },
      "source": [
        "#### 1.2. Which modifications make gradient boosting **robust against overfitting**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zAnH_KU-qip"
      },
      "source": [
        "Gredient Boosting is not robust against overfitting the training data as it is a greedy algorithm. This problem can be resolved by using regualarization methods which penalize different aspects of the algorithm. The following methods can be used:\n",
        "- **Tree constraints:** The idea is that is the trees are more constrained, more trees need to be constructed. The constraints can be imposed on \n",
        "    - the number of trees (~\"keep on adding trees until no improvement is observed\"), \n",
        "    - tree depth (~\"shorter trees are preferred as deeper trees are considered more complex\"),\n",
        "    - number of nodes/leaves of tree and\n",
        "    - number of observations per split and minimum improvement to loss.\n",
        "\n",
        "- **Weighted Updates:** The prediction of each tree is weighed by a learning rate or shrinkage to slow down the learning by the algorithm. Shrinkage reduces the influence of each individual tree and leaves space for future trees to improve the model.\n",
        "\n",
        "\n",
        "- **Stochastic Gradient Boosting:** The method aims at reducing the correlation of the trees in the sequence of trees. This is achieved by using only a subsample of the training data to fit the  base learner.\n",
        "\n",
        "\n",
        "- **Penalized Gradient Boosting:** Regression trees (a variant of decision trees which contain only numeric values at leaf nodes) can be used in GB. The leaf values act as weights and can be regularised using $L_1$ or $L_2$ regularization to prevent overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyw9E17lFKxz"
      },
      "source": [
        "#### 1.3. Using the `titanic_survival_dataset.csv`, train the following models using nested cross validation while optimizing a selected number of hyperparameters in the inner loop using grid search, then compute the probabilities of your targets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdkdJx3c-ycE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4b6986b8-4b27-4847-b8c9-415a97d87c15"
      },
      "source": [
        "# Load the dataset\n",
        "titanic_data = pd.read_csv('titanic_survival_data.csv', index_col=\"PassengerId\")\n",
        "titanic_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>no_cabin</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Pclass  Sex   Age  SibSp  ...     Fare  Embarked  no_cabin  Label\n",
              "PassengerId                            ...                                    \n",
              "1                 3    0  22.0      1  ...   7.2500         0         2      0\n",
              "2                 1    1  38.0      1  ...  71.2833         1         1      1\n",
              "3                 3    1  26.0      0  ...   7.9250         0         2      1\n",
              "4                 1    1  35.0      1  ...  53.1000         0         1      1\n",
              "5                 3    0  35.0      0  ...   8.0500         0         2      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaF0u7bfXh8W"
      },
      "source": [
        "# Sepearate features and target (which is stored in column 'Label')\n",
        "y = titanic_data['Label'].ravel()\n",
        "X = titanic_data.drop(columns = ['Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhfmrS-AFOra"
      },
      "source": [
        "#### 1.3.a) Random forest, optimizing the number of estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53pNibdz_vh7"
      },
      "source": [
        "# Initialize the RF classifier and a parameter grid for the grid search\n",
        "Random_Forest = RandomForestClassifier()\n",
        "p_grid_random_forest = {'n_estimators': [100, 150, 200, 300, 400]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2WoTW8B_xzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3c5ad9-e3f1-45e2-d496-ff79de3811a2"
      },
      "source": [
        "# Inner Fold - to obtain the best hyperparameters\n",
        "Random_Forest_Fit = GridSearchCV(\n",
        "    estimator = Random_Forest,\n",
        "    param_grid = p_grid_random_forest,\n",
        "    cv = KFold(shuffle = True),\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "Random_Forest_Fit.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   10.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'n_estimators': [100, 150, 200, 300, 400]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81oe6w3d_6QW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95cebe00-e1e2-4dc4-b4b5-3c257a70781a"
      },
      "source": [
        "# Outer Fold - to perform cross validation based on metrics and compute the probabilities of the target\n",
        "random_forest_prediction_prob = cross_val_predict(\n",
        "    estimator = Random_Forest_Fit,\n",
        "    X = X,\n",
        "    y = y,\n",
        "    cv = KFold(shuffle = True),\n",
        "    method = 'predict_proba', # To obtain prediction probabilities in result\n",
        "    verbose = 1\n",
        ")\n",
        "random_forest_prediction_prob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.5s finished\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   50.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.706  , 0.294  ],\n",
              "       [0.01   , 0.99   ],\n",
              "       [0.615  , 0.385  ],\n",
              "       ...,\n",
              "       [0.605  , 0.395  ],\n",
              "       [0.155  , 0.845  ],\n",
              "       [0.98375, 0.01625]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT5fcXYbFQKJ"
      },
      "source": [
        "#### 1.3.b) Gradient boosting, optimizing boosting steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqLsNOin_-zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ee8009-859d-4f8a-9add-f7036fde0f95"
      },
      "source": [
        "# Initialize the GB classifier and a parameter grid for the grid search\n",
        "GB = GradientBoostingClassifier()\n",
        "p_grid_gb = {'n_estimators': [10, 50, 100, 200, 300]}\n",
        "\n",
        "# Inner Fold - to obtain the best hyperparameters\n",
        "GB_Best_Clf = GridSearchCV(\n",
        "    estimator = GB,\n",
        "    param_grid = p_grid_gb,\n",
        "    cv = KFold(shuffle = True),\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "GB_Best_Clf.fit(X, y)\n",
        "\n",
        "# Outer Fold - to perform cross validation based on metrics and compute the probabilities of the target\n",
        "gb_prediction_prob = cross_val_predict(\n",
        "    estimator = GB_Best_Clf,\n",
        "    X = X,\n",
        "    y = y,\n",
        "    cv = KFold(shuffle = True),\n",
        "    method = 'predict_proba', # To obtain prediction probabilities in result\n",
        "    verbose = 1\n",
        ")\n",
        "gb_prediction_prob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   16.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.78829091, 0.21170909],\n",
              "       [0.05449812, 0.94550188],\n",
              "       [0.49750538, 0.50249462],\n",
              "       ...,\n",
              "       [0.54399186, 0.45600814],\n",
              "       [0.10972886, 0.89027114],\n",
              "       [0.9760037 , 0.0239963 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFoW86HYFRQr"
      },
      "source": [
        "#### 1.3.c) Lasso penalized logistic regression, optimizing $L_1$ regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8u4nd5FAH8d"
      },
      "source": [
        "# Converting computed prediction probabilities to dataframes\n",
        "lr_prob_result = pd.DataFrame(lr_prediction_prob, columns = ['0', '1'])\n",
        "gb_prob_result = pd.DataFrame(gb_prediction_prob, columns = ['0', '1'])\n",
        "rf_prob_result = pd.DataFrame(random_forest_prediction_prob, columns = ['0', '1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTrbd1slCDb7"
      },
      "source": [
        "(Using a large parameter grid results in an extended computation time. We advise using a maximum of *five* values per hyperparameter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqZp3FIBD7P_"
      },
      "source": [
        "#### 3.3. How does the neural network perform in comparison to the models in the calibration curve from the previous task and plot the results alongside the other models in the calibration plot?"
      ]
    }
  ]
}