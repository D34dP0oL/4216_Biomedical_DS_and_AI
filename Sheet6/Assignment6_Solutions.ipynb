{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Assignment6_Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/D34dP0oL/4216_Biomedical_DS_and_AI/blob/main/Sheet6/Assignment6_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UnHoHsFop-8"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import random as rand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUswbzmRCHbj"
      },
      "source": [
        "data_file_path = \"https://raw.githubusercontent.com/D34dP0oL/4216_Biomedical_DS_and_AI/main/Datasets/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx0G72bGl7xc"
      },
      "source": [
        "## Biomedical Data Science & AI\n",
        "\n",
        "## Assignment 6\n",
        "\n",
        "#### Group members:  Fabrice Beaumont, Fatemeh Salehi, Genivika Mann, Helia Salimi, Jonah"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fhYMe5ml7xo"
      },
      "source": [
        "---\n",
        "### Exercise 1 - NMF clustering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgUkN-nGziCe"
      },
      "source": [
        "#### 1.1. Write an algorithm to showcase the working of Non-negative matrix factorization (NMF)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appoDszfFI5l"
      },
      "source": [
        "#### 1.2. Mention the pros and cons of NMF as well as one of its applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyw9E17lFKxz"
      },
      "source": [
        "#### 1.3. Use the nimfa package for NMF clustering on gene expression data to cluster genes into groups. Use the parameters (10 ranks, 50 maximum iterations and 25 runs) to compute the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhfmrS-AFOra"
      },
      "source": [
        "#### 1.3.a) From the average connectivity matrix across multiple runs compute consensus matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT5fcXYbFQKJ"
      },
      "source": [
        "#### 1.3.b) Produce a heatmap with a dendrogram from the clustering results you obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFoW86HYFRQr"
      },
      "source": [
        "#### 1.3.c) What are the consequences of selecting a rank value that is too small or too large? Implement a method showing how you can optimize the value of the rank to be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NExXYSYPFL78"
      },
      "source": [
        "#### 1.4. Inform yourself about Non-Negative Matrix Tri-Factorization (NMTF). What is the primary difference between NMF and NMTF and what does it achieve?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnWW-nzRFNGQ"
      },
      "source": [
        "#### 1.5. PCA and NMF are both matrix factorization methods, how do they differ from each other? Describe a situation where PCA is favored over NMF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v3MrpiqElLz"
      },
      "source": [
        "---\n",
        "### Exercise 2 - Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsbQAaMbY7q1"
      },
      "source": [
        "#### 2.1. The type of machine learning (e.g. supervised learning, unsupervised learning, etc.) applied depends on the problem at hand. Assume that we have an `Alzheimer's disease (AD) dataset` where rows represent 500 participants and columns represent 100 different collected measurements for each participant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjUHF7RUE3Cp"
      },
      "source": [
        "##### 2.1.a) You are asked to train a model that can predict whether a participant is healthy or AD. Mention the type of machine learning you would use for this case scenario and elaborate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDPR_PU5E6M5"
      },
      "source": [
        "##### 2.1.b) Assume that we do not have any information about the diagnosis of each participant. This time we would like to divide our participants into groups based on the features that we have in hand. What type of machine learning would be appropriate for this scenario and elaborate?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIcUlAxgE7Wd"
      },
      "source": [
        "##### 2.1.c) Imagine that the shape of our dataset is *(100, 600)*, mention one pre-processing step that you would take to carry out the tasks *2.1.a)* and *2.1.b)*?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phw_HR48Ey9z"
      },
      "source": [
        "#### 2.2. Generate a pipeline in scikit learn using the following code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4jSTy2jG6FZ"
      },
      "source": [
        "####################### Given Code Snippet ############################\n",
        "# polynomial_features = PolynomialFeatures(degree=15, include_bias=False)\n",
        "# linear_regression = LinearRegression()\n",
        "\n",
        "# pipeline = Pipeline([\n",
        "#     (\"polynomial_features\", polynomial_features),\n",
        "#     (\"linear_regression\", linear_regression)\n",
        "# ])`\n",
        "#######################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QTFGk1zHUv9"
      },
      "source": [
        "##### 2.2.a) Using the Fish dataset provided, identify the quality of fit of the pipeline for the dataset (use the weight as the response variable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAfsAnU8HaY9"
      },
      "source": [
        "##### 2.3.b) If the pipeline produces a badly fit model for the dataset, list some methods to improve the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FT2Xl_AE1Fk"
      },
      "source": [
        "#### 2.3. In this exercise we will compare the accuracy of different methods on a high-dimensional ($p>>n$) dataset. Load the leukemia_small.csv and extract the class labels from the column names (2 classes, `AML` and `ALL`).Randomly split the data into *70%* training and *30%* test.\n",
        "\n",
        "**Hint:** Use the `train_test_split` function from scikit-learn to define the test_size and\n",
        "set `random_state=1` for better reproducibility.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W8jwBlpE9z7"
      },
      "source": [
        "##### 2.3.a) Fit a logistic regression (no penalization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg4ZR1dOE_gU"
      },
      "source": [
        "##### 2.3.b) Fit multiple $l_1$-penalized logistic regressions ($\\lambda \\in \\{ 0.001,\\ 0.01,\\  0.1,\\ \n",
        "1,\\  10,\\ 100\\}$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33sv9n9aFApt"
      },
      "source": [
        "##### 2.3.c) Fit multiple $l_2$-penalized logistic regressions ($\\lambda \\in \\{ 0.001,\\ 0.01,\\  0.1,\\ \n",
        "1,\\  10,\\ 100\\}$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY1tnymZFBbW"
      },
      "source": [
        "##### 2.3.d) For the models from *2.3.a)*, *2.3.b)*, and *2.3.c)* measure the performance on the training and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G_aB_cVFCbN"
      },
      "source": [
        "##### 2.3.e) Using *2.3.d)* report the performances with one scatterplot for each approach (one scatterplot for each: unpenalized, $l_1$, $l_2$), with the regularization constant on the $x$-axis and the accuracy on the $y$-axis, train and test set colored differently, proper axis labels and a legend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswnbGnvFDY5"
      },
      "source": [
        "##### 2.3.f) Which method in combination with which parameter gives the best results on the test set?"
      ]
    }
  ]
}