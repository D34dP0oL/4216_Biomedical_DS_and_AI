{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Assignment7_Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabriceBeaumont/4216_Biomedical_DS_and_AI/blob/main/Sheet7/Assignment7_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UnHoHsFop-8"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import random as rand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUswbzmRCHbj"
      },
      "source": [
        "def get_dataset_from_github(filename, index_col_str=None, header_str='infer'):    \n",
        "    data_file_path = \"https://raw.githubusercontent.com/D34dP0oL/4216_Biomedical_DS_and_AI/main/Datasets/\"\n",
        "    if index_col_str is None and header_str == 'infer':\n",
        "      data = pd.read_csv(data_file_path + filename)\n",
        "    elif index_col_str is None:\n",
        "        data = pd.read_csv(data_file_path + filename, header=header_str)\n",
        "    elif header_str == 'infer':\n",
        "      data = pd.read_csv(data_file_path + filename, index_col=index_col_str)\n",
        "    else:\n",
        "      data = pd.read_csv(data_file_path + filename, index_col=index_col_str, header=header_str)\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx0G72bGl7xc"
      },
      "source": [
        "## Biomedical Data Science & AI\n",
        "\n",
        "## Assignment 7\n",
        "\n",
        "#### Group members:  Fabrice Beaumont, Fatemeh Salehi, Genivika Mann, Helia Salimi, Jonah"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fhYMe5ml7xo"
      },
      "source": [
        "---\n",
        "### Exercise 1 - Elastic Net & Nested Cross-Validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgUkN-nGziCe"
      },
      "source": [
        "#### 1.1. Using the `titanic_survival_data.csv` dataset, train a logistic regression model with elastic net penalization to demonstrate the pros and cons of the different data splitting methods and give a short description on what you observe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWG_h9C_o2bZ"
      },
      "source": [
        "##### 1.1.a) Report the accuracy of data splitting with a test size of $0.2$ and random state as $1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHb-R-M0o4d4"
      },
      "source": [
        "##### 1.1.b) Plot the boxplot for the accuracy of the **$K$-fold cross validation** with $5$ splits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKQMVXZLo6A1"
      },
      "source": [
        "##### 1.1.c) Plot the boxplot for the accuracy of the **Stratified-$K$-fold cross validation** with $5$ splits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkWfRRu6o7HE"
      },
      "source": [
        "##### 1.1.d) Inform yourself about **leave-one-out cross-validation** (**LOOCV**). Implement LOOCV and mention the pros and cons of the method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appoDszfFI5l"
      },
      "source": [
        "#### 1.2. Use the nested cross validation to train a logistic regression with elastic net penalization (`leukemia_small.csv`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhfmrS-AFOra"
      },
      "source": [
        "##### 1.2.a) Split the data into training and test samples using an appropriate cross validation method, and in the inner loop carry out **hyperparameter optimization**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CJhiLbSpoOm"
      },
      "source": [
        "##### 1.2.b) Compute the area under the ROC curve (**AUC-ROC**) and the area under the precision-recall curve (**AUC-PR**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r290kRylppoH"
      },
      "source": [
        "##### 1.2.c) Plot separate boxplots for the two performance metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NExXYSYPFL78"
      },
      "source": [
        "#### 1.3. In your own words, explain how each of the following metrics can be used to assess the performance of a model and then calculate each metric using the following confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB9TtcYdqJZH"
      },
      "source": [
        " _           | Predicted No | Predicted Yes |\n",
        "---|---|---\n",
        "Actual No    | $250$        | $20$          |\n",
        "Actual Yes   | $30$         | $100$         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnWW-nzRFNGQ"
      },
      "source": [
        "##### 1.3.a) Recall\n",
        "\n",
        "With recall we can measure what percentage of the total positives are predicted to be positive, so in other words, it gives us a measure of the true positive rate.\n",
        "\n",
        "Calculation:\n",
        "\n",
        "$Recall = \\frac{TP}{TP+FN} = \\frac{100}{100+30} \\approx 77\\%$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11_ebbYlp8cS"
      },
      "source": [
        "##### 1.3.b) $F_1$\n",
        "\n",
        "The F1-Score measures the balance between precision and recall. While the recall measures how many false negatives we have, the precision give us an indication of the number of false positives. If the model has high recall and precision this leads to a high F1-Score. The F1-Score is especially useful as a performance measure if we have an uneven class distribution.\n",
        "\n",
        "Calculation:\n",
        "\n",
        "$Precision = \\frac{TP}{TP+FP} = \\frac{100}{100+20} \\approx 83\\%$\n",
        "\n",
        "$F1 = 2\\cdot \\frac{Precision \\cdot Recall}{Precision + Recall} = 2\\cdot \\frac{0.833\\cdot 0.769}{0.833 + 0.769} \\approx 0.8$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvzK-GqDp-H-"
      },
      "source": [
        "##### 1.3.c) Balanced Accuracy (BAC)\n",
        "\n",
        "Balanced Accuracy is the arithmetic mean between recall (also called sensitivity/true positive rate in this scope) and specificity. The specificity is a measure for the true negative rate. Like the F1-Score the balanced accuracy is especially useful to measure the performance of a model when the classes are imbalanced as it attempts to account for the imbalance in classes.\n",
        "\n",
        "Calculation:\n",
        "\n",
        "$Specificity = \\frac{TN}{TN+FP} = \\frac{250}{250+20} \\approx 93\\%$\n",
        "\n",
        "$BAC = \\frac{TPR + TNR}{2} = \\frac{0.769 + 0.926}{2} \\approx 0.85$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpr7R7PRp_KB"
      },
      "source": [
        "##### 1.3.d) Matthews Correlation Coefficient (MCC)\n",
        "\n",
        "Matthew Correlation Coefficient gives us a measure of the differences between the real values and the predicted values. The difference takes true positives, false positives, true negatives and false negatives into account and returns a high score only if for all four measures the model has good results.\n",
        "\n",
        "Calculation:\n",
        "\n",
        "$MCC = \\frac{TP\\cdot TN - FP\\cdot FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}} = \\frac{100\\cdot 250 - 20\\cdot 30}{\\sqrt{(100+20)(100+30)(250+20)(250+30)}} \\approx 0.71$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v3MrpiqElLz"
      },
      "source": [
        "---\n",
        "### Exercise 2 - SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsbQAaMbY7q1"
      },
      "source": [
        "#### 2.1. Inform yourself about **SVM** and briefly explain the working strategy of linear SVM and why maximizing the margin is a good strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FT2Xl_AE1Fk"
      },
      "source": [
        "#### 2.2. Inform yourself about the non-linearity problem for classifiers. Briefly explain how SVM uses **kernel trick** to overcome this issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W8jwBlpE9z7"
      },
      "source": [
        "---\n",
        "### Exercise 3 - Random Forest\n",
        "\n",
        "For the following questions, use `random_seed = 1` for better reproducibility of your\n",
        "answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg4ZR1dOE_gU"
      },
      "source": [
        "#### 3.1. Load the breast cancer dataset from sklearn to your Jupyter notebook. Use label encoding to convert your target variable “class” into numerical form. Split the dataset using a $5$-fold cross validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswnbGnvFDY5"
      },
      "source": [
        "#### 3.2. Set up a parameter grid and use grid search with $5$-fold cross validation to identify the best hyperparameter values used to fit a random forest classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_REmdztsGyT"
      },
      "source": [
        "#### 3.3. Use the best hyperparameters from *2)* to fit the final model. Predict the classes of the test set and count the number of samples assigned to each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2qVdnYgsH37"
      },
      "source": [
        "#### 3.4. Print the importance of each feature in descending order. Identify the top five features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd1K747ssJBm"
      },
      "source": [
        "#### 3.5. Mention a case when permutation feature importance is favored over impurity-based feature importance. Use permutation importance to print the importances of your features in a descending order. Compare your answer with that of *4)*. Do you notice any differences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEewS1cBsKR4"
      },
      "source": [
        "#### 3.6. In your own words, explain the **bootstrapping technique** and mention how random forest benefits from its application."
      ]
    }
  ]
}